# config/nomic-256.yaml
# Nomic Embed v1.5 con MRL 256 dims (RECOMENDADO)
# Balance óptimo: 103% precisión vs 768, 67% menos storage

components:
  format_detector:
    class: "src.detectors.multi_pattern.MultiPatternDetector"

  importers:
    - class: "src.importers.chatgpt.ChatGPTImporter"
      formats: ["chatgpt", "openai"]
      config: {}

  normalizer:
    class: "src.normalizers.markdown.MarkdownNormalizer"
    config:
      use_markitdown: true
      fallback_on_error: true
      preserve_code_blocks: true

  classifier:
    class: "src.classifiers.rule_based.RuleBasedClassifier"
    config: {}

  vectorizer:
    class: "src.vectorizers.nomic_embed.NomicEmbedVectorizer"
    config:
      model: "nomic-ai/nomic-embed-text-v1.5"
      dimension: 256
      batch_size: 32
      device: "cuda"

  storage:
    class: "src.storage.sqlite_vector.SQLiteVectorStorage"
    config:
      database: "data/recall.db"
      dimension: 256

pipeline:
  stages:
    - name: "import"
      components: ["format_detector", "importers"]
    - name: "normalize"
      components: ["normalizer"]
      gc_after: false
    - name: "classify"
      components: ["classifier"]
      gc_after: false
    - name: "vectorize"
      components: ["vectorizer"]
      gc_after: true
      cuda_empty_cache: true
    - name: "persist"
      components: ["storage"]

memory:
  concurrent_models: false
  force_gc_between_stages: true
  cuda_empty_cache_between_stages: true
  memory_profiling: true
